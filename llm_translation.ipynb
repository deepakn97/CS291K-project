{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from constants import *\n",
    "\n",
    "# Open source\n",
    "with open(Path(DATASET_DIR, 'wmt14_en_train.src'), 'r') as f:\n",
    "    source_train_dataset = []\n",
    "    for sentence in f:\n",
    "        source_train_dataset.append([int(x) for x in sentence.split(' ')[:-1]])\n",
    "\n",
    "# Open target\n",
    "with open(Path(DATASET_DIR, 'wmt14_fr_train.trg'), 'r') as f:\n",
    "    target_train_dataset = []\n",
    "    for sentence in f:\n",
    "        target_train_dataset.append([int(x) for x in sentence.split(' ')[:-1]])\n",
    "\n",
    "# Open source\n",
    "with open(Path(DATASET_DIR, 'wmt14_en_test.src'), 'r') as f:\n",
    "    source_test_dataset = []\n",
    "    for sentence in f:\n",
    "        source_test_dataset.append([int(x) for x in sentence.split(' ')[:-1]])\n",
    "\n",
    "# Open target\n",
    "with open(Path(DATASET_DIR, 'wmt14_fr_test.trg'), 'r') as f:\n",
    "    target_test_dataset = []\n",
    "    for sentence in f:\n",
    "        target_test_dataset.append([int(x) for x in sentence.split(' ')[:-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        unk_token=\"<|unk|>\",\n",
    "        bos_token=\"<|bos|>\",\n",
    "        eos_token=\"<|eos|>\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the few-shot prompt\n",
    "few_shot_prompt = \"Translate the following sentence from English to French \\n\\n\"\n",
    "n_few_shot = 5\n",
    "bos_token = 50257\n",
    "eos_token = 50258\n",
    "\n",
    "for i in range(n_few_shot):\n",
    "    source = source_train_dataset[i]\n",
    "    source = [token for token in source if (token != bos_token and token != eos_token)]\n",
    "    source = tokenizer.decode(source)\n",
    "    few_shot_prompt += f\"English: {source} \\n\"\n",
    "\n",
    "    target = target_train_dataset[i]\n",
    "    target = [token for token in target if (token != bos_token and token != eos_token)]\n",
    "    target = tokenizer.decode(target)\n",
    "    few_shot_prompt += f\"French: {target} \\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the last step \n",
    "i = 0\n",
    "\n",
    "source = source_test_dataset[i]\n",
    "source = [token for token in source if (token != bos_token and token != eos_token)]\n",
    "source = tokenizer.decode(source)\n",
    "\n",
    "prompt = few_shot_prompt + f\"English: {source} \\n\"\n",
    "prompt += \"French: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the query(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_keys_file = \"keys.txt\"\n",
    "with open(api_keys_file, 'r') as f:\n",
    "    keys = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpernAIParams:\n",
    "    model=\"code-davinci-002\"\n",
    "    max_generation_tokens=128\n",
    "    temperature=0\n",
    "    top_p=1\n",
    "    n=1\n",
    "    top_p=1\n",
    "    stop='\\n'\n",
    "    presence_penalty=0\n",
    "    best_of=10\n",
    "    \n",
    "open_ai_params = OpernAIParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "def make_query(prompt, params):\n",
    "\n",
    "    result = None\n",
    "    key_index = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    while result is None:\n",
    "        try:\n",
    "            key_index = (key_index + 1) % len(keys)\n",
    "            result = openai.Completion.create(\n",
    "                api_key=keys[key_index],\n",
    "                prompt=prompt,\n",
    "                model=params.model,\n",
    "                max_tokens=params.max_generation_tokens,\n",
    "                temperature=params.temperature,\n",
    "                n=params.n,\n",
    "                top_p=params.top_p,\n",
    "                stop=params.stop,\n",
    "                presence_penalty=params.presence_penalty,\n",
    "                best_of=params.best_of\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e, \"Retry with key index: \", key_index)\n",
    "            time.sleep(5)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return result, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = make_query(prompt, open_ai_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = result['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spectaculaire saut en \"wingsuit\" au-dessus de Bogota '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('CS291K-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7d541b5918165d5adb7c6fe2fda77ad0419e8950cc274b49b3fb38f2077d078"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
